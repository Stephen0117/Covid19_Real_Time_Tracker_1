{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import datetime\n",
    "import json\n",
    "from datetime import date\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns of the csv file\n",
    "COLS = ['id', 'created_at', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'twitter_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-998bb58916f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"twitter_data.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitter_data.txt'"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for line in open(\"twitter_data.txt\",\"r\"):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDB = {}\n",
    "for var in COLS:\n",
    "    Text = []\n",
    "    for i in range(0,len(tweets)):\n",
    "        Text.append(tweets[i][var])\n",
    "    RDB[var]=Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cleaning & Convert Twitter Data to dataframe\n",
    "\n",
    "def TwitterCleaning(DB):\n",
    "    \n",
    "    HDB = pd.DataFrame(DB)\n",
    "    \n",
    "    #Converting Datetime\n",
    "    HDB['created_at'] = pd.to_datetime(HDB['created_at'])\n",
    "\n",
    "    #Cleaning HTML Tags\n",
    "    HDB['text']=HDB['text'].apply(lambda x: re.sub('<[^>]*>','',x))\n",
    "\n",
    "    #Cleaning URL link\n",
    "    HDB['text']=HDB['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "\n",
    "    #Cleaning punctuations\n",
    "    HDB['text']=HDB['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    #lower Case\n",
    "    HDB['text']=HDB['text'].apply(lambda x: x.lower())\n",
    "    \n",
    "    #Remove Emoji\n",
    "    HDB['text']=HDB['text'].apply(lambda x: emoji_pattern.sub(r'',x))\n",
    "   \n",
    "    return HDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FDB = TwitterCleaning(RDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDB.to_csv(\"Cleaned_Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Cases per 1 million people</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>3845607</td>\n",
       "      <td>495</td>\n",
       "      <td>1282930</td>\n",
       "      <td>269564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>United States</td>\n",
       "      <td>1289235</td>\n",
       "      <td>3912</td>\n",
       "      <td>174697</td>\n",
       "      <td>76537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Spain</td>\n",
       "      <td>221447</td>\n",
       "      <td>4702</td>\n",
       "      <td>128511</td>\n",
       "      <td>26070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Italy</td>\n",
       "      <td>215858</td>\n",
       "      <td>3583</td>\n",
       "      <td>96276</td>\n",
       "      <td>29958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>206715</td>\n",
       "      <td>3112</td>\n",
       "      <td>â€”</td>\n",
       "      <td>30615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Russia</td>\n",
       "      <td>187859</td>\n",
       "      <td>1280</td>\n",
       "      <td>26608</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Germany</td>\n",
       "      <td>169430</td>\n",
       "      <td>2038</td>\n",
       "      <td>135918</td>\n",
       "      <td>7392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>France</td>\n",
       "      <td>137779</td>\n",
       "      <td>2054</td>\n",
       "      <td>55027</td>\n",
       "      <td>25897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>135773</td>\n",
       "      <td>642</td>\n",
       "      <td>55350</td>\n",
       "      <td>9190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>133721</td>\n",
       "      <td>1608</td>\n",
       "      <td>82984</td>\n",
       "      <td>3641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Iran</td>\n",
       "      <td>103135</td>\n",
       "      <td>1238</td>\n",
       "      <td>82744</td>\n",
       "      <td>6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>China</td>\n",
       "      <td>82886</td>\n",
       "      <td>59</td>\n",
       "      <td>77993</td>\n",
       "      <td>4633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Canada</td>\n",
       "      <td>64922</td>\n",
       "      <td>1709</td>\n",
       "      <td>29247</td>\n",
       "      <td>4408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Peru</td>\n",
       "      <td>58526</td>\n",
       "      <td>1821</td>\n",
       "      <td>18388</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>India</td>\n",
       "      <td>56342</td>\n",
       "      <td>41</td>\n",
       "      <td>16540</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>51420</td>\n",
       "      <td>4462</td>\n",
       "      <td>12980</td>\n",
       "      <td>8415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>41774</td>\n",
       "      <td>2394</td>\n",
       "      <td>â€”</td>\n",
       "      <td>5288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>33731</td>\n",
       "      <td>986</td>\n",
       "      <td>7798</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>30298</td>\n",
       "      <td>1736</td>\n",
       "      <td>3433</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>30126</td>\n",
       "      <td>3509</td>\n",
       "      <td>25900</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        Date        Location Confirmed  \\\n",
       "0            0  2020-05-08       Worldwide   3845607   \n",
       "1            1  2020-05-08   United States   1289235   \n",
       "2            2  2020-05-08           Spain    221447   \n",
       "3            3  2020-05-08           Italy    215858   \n",
       "4            4  2020-05-08  United Kingdom    206715   \n",
       "5            5  2020-05-08          Russia    187859   \n",
       "6            6  2020-05-08         Germany    169430   \n",
       "7            7  2020-05-08          France    137779   \n",
       "8            8  2020-05-08          Brazil    135773   \n",
       "9            9  2020-05-08          Turkey    133721   \n",
       "10          10  2020-05-08            Iran    103135   \n",
       "11          11  2020-05-08           China     82886   \n",
       "12          12  2020-05-08          Canada     64922   \n",
       "13          13  2020-05-08            Peru     58526   \n",
       "14          14  2020-05-08           India     56342   \n",
       "15          15  2020-05-08         Belgium     51420   \n",
       "16          16  2020-05-08     Netherlands     41774   \n",
       "17          17  2020-05-08    Saudi Arabia     33731   \n",
       "18          18  2020-05-08         Ecuador     30298   \n",
       "19          19  2020-05-08     Switzerland     30126   \n",
       "\n",
       "   Cases per 1 million people Recovered  Deaths  \n",
       "0                         495   1282930  269564  \n",
       "1                        3912    174697   76537  \n",
       "2                        4702    128511   26070  \n",
       "3                        3583     96276   29958  \n",
       "4                        3112         â€”   30615  \n",
       "5                        1280     26608    1723  \n",
       "6                        2038    135918    7392  \n",
       "7                        2054     55027   25897  \n",
       "8                         642     55350    9190  \n",
       "9                        1608     82984    3641  \n",
       "10                       1238     82744    6486  \n",
       "11                         59     77993    4633  \n",
       "12                       1709     29247    4408  \n",
       "13                       1821     18388    1627  \n",
       "14                         41     16540    1886  \n",
       "15                       4462     12980    8415  \n",
       "16                       2394         â€”    5288  \n",
       "17                        986      7798     219  \n",
       "18                       1736      3433    1654  \n",
       "19                       3509     25900    1518  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('covid-19_20200508.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                     0\n",
      "Date                           0\n",
      "Location                       0\n",
      "Confirmed                      2\n",
      "Cases per 1 million people     7\n",
      "Recovered                     18\n",
      "Deaths                         5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = [\"n/a\", \"na\", \"â€”\"]\n",
    "df = pd.read_csv(\"covid-19_20200508.csv\", na_values = missing_values)\n",
    "\n",
    "print (df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    0\n",
      "Date                          0\n",
      "Location                      0\n",
      "Confirmed                     0\n",
      "Cases per 1 million people    0\n",
      "Recovered                     0\n",
      "Deaths                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Confirmed'] = df['Confirmed'].fillna(0).astype(int)\n",
    "df['Cases per 1 million people'] = df['Cases per 1 million people'].fillna(0).astype(int)\n",
    "df['Recovered'] = df['Recovered'].fillna(0).astype(int)\n",
    "df['Deaths'] = df['Deaths'].fillna(0).astype(int)\n",
    "\n",
    "print (df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"Cleaned_Covid_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
